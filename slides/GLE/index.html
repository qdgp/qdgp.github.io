<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<title>comprehensve exam</title>
		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/serif.css">
		<style>	
		div.model {
			display: flex;
			justify-content: space-between;
			align-items: center; /* This will vertically center the content */
			margin: 20px 0;
			padding: 10px;
			border: 1px solid #ddd;
			border-radius: 5px;
		}
		div.model .name {
			margin: 0;
			flex: 1;
			color: #444;
			display: flex;
			align-items: center; /* This will vertically center the text */
			justify-content: flex-end; /* This will align the text to the right */
			padding-right: 20px; /* Some spacing between the name and the equation */
		}
		div.model .equation {
			flex: 2;
		}
			figcaption {
			  color: black;
			  font-style: italic;
			  padding: 2px;
			  font-size:large;
			  text-align: center;
			}
			.particle {
				fill: blue;
				stroke: black;
				stroke-width: 1;
			}
			.bond {
				stroke: black;
				stroke-width: 2;
			}
			cite {
				font-size: 0.4em; /* Adjust the font size as needed */
				display: block; /* Optional: To make the citation appear on a new line */
				color:#444
			}
			.theorem, .proposition {
				border: 1px solid #000;
				padding: 10px;
				margin: 10px 0;
			}
			.theorem {
				background-color: #f0f0f0;
			}
			.proposition {
				background-color: #e0e0e0;
			}
			.theorem h4, .proposition h4 {
				margin: 0;
				font-size: 1em;
			}
			.content {
				margin-top: 5px;
				font-size: 0.6em;
			}
		</style>
		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
		<script src="js/d3.v6.min.js"></script>
		<script src="../../MathJax/MathJax.js?config=TeX-AMS-MML_SVG"></script>
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({
			  TeX: {
				Macros: {
				  bm: ["{\\mathbf{#1}}", 1],
   				  mb: ["{\\mathbf{#1}}", 1],
				diff: "\\mathop{}\\!\\mathrm{d}",
				MLMN: "\\mathcal{L}_\\mathcal{N}",
				bz: "\\mathbf{z}",
				br: "\\mathbf{r}",
				bs: "\\mathbf{s}",
				bF: "\\mathbf{F}",
				intd: "\\mathrm{d}",
				mbm:"\\mathbf{m}",
				}
			  }
			});
		  </script>
		<script type="text/javascript">
		window.PlotlyConfig = {MathJaxConfig: 'local'};
		</script>
		<script src="js/plotly-latest.min.js"></script>
		<script src="./figure/md.js">
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<div style="text-align: center;">
						<h4>
							Consensus-based construction of high-dimensional free energy surface
						</h4>
					</div>
					<div style="margin-left: auto; text-align: left; font-size: 0.7em;">
						<p>
							lyuliyao <br>
							Department of Computational Mathematics, Science & Engineering <br>
							Michigan State University
						</p>
					</div>
					<aside class="notes">
						Today, I’m going to talk Consensus-based construction of high-dimensional free energy surface.
					</aside>
                </section>
				<section data-auto-animate>
					<h4>
						Free Energy Surface (FES) of Collective variables (CVs)
					</h4>
					<div style="display: flex; justify-content: center; align-items: center;">
					<div>
						<small>
							\[
							\begin{aligned}
							& \text{FES}:& & A(\bz)  =  -\frac{1}{\beta}\ln \rho(\bz)\\
							& \text{PDF}:& & \rho(\bz) =  \frac{\int e^{(-\beta U(\br))} \delta(\bs(\br)-\bz) \intd \br}{Z}\\
							& \text{CVs}:& & \bz = \bs(\br)\\
							& \text{Potential}:  & &U(\br)   \text{ of the micro-scale coordinates } \br \\
							\end{aligned}
							\]
						</small>
					</div>
					<div>
						<figure>
							<p>
								<img  style="width:80%" src="./figure/FES.png">
							</p>
						</figure>
						<cite>
							Dill, Ken A., and Justin L. MacCallum. "The protein-folding problem, 50 years on." science 338.6110 (2012): 1042-1046.
						</cite>
					</div>
					</div>
					<aside class="notes">
						<p>
							<p> Constructing free energy surface is an important problem for many chemical and biology problems</p>
							<p> It contains many important information of the complex system.</p>
							<p>For example, the minimum and the local minima usually represents the stable and metastable state of the system</p>
							<p>FES is also important to some kenitic propeties such as transtion path or energy barrier between two metastable state.</p>
							<p>Usually reconstruct FES is based on the bolzman relation</p>
							<p> It relates the FES with the PDF of finding a particle in a particular state.</p>
							<p>The accurate construction of FES remains a practical challenge due to the high dimensionality and the prevalence of energy barriers</p>
						</p>
					</aside>
				</section>
				<section data-auto-animate>
					<h4>Main Challenges</h4>
					<div style="display: flex; justify-content: center; align-items: center;">

						<div>
							<div data-id="EB">
								<p>
									The Prevalence of Energy Barriers <br>
								</p>
							</div>
							<div data-id="EBP" style="font-size: 0.8em;">
								<p>
									<span style="color: #C82423;"> Explore the phase space by overcoming energy barriers </span> 
								</p>
							</div>
							<div style="font-size: 0.8em;">
								<p>
									<sapn style="color:blue;">Existing Method</sapn>: Umbrella sampling, Histogram reweighting, Metadynamics, Variational enhanced sampling, Temperature-accelerated molecular dynamics
									and Adiabatic free energy dynamics.
								</p>
							</div>
						</div>
						<div>
							<figure>
								<img style="width:1500px; object-fit: cover;" src="./figure/MetaD.png">
							</figure>
						</div>
					</div>
					<aside class="notes">
						<p>The prevalence of energy barriers means the transtion between two metastable states is a rare event.</p>
						<p>The probability of the trasition happens will decrease exponentially with the height of the energy bar.</p>
						<p> Several ingenious methods based on importance sampling have been developed, such as umbrella sampling, histogram reweighting,metadynamics, variational enhanced sampling</p>
						<p> They typically add a bias potential here to increase the probability of transition from one state to the other.</p>
						<p> The finial reconstruction of the FES is based on the PDF estimation under the bias potential</p>
						<p> Another type of method is based on increasing the temperature artificially, the increased the temperature of decrease the energy barrier and increase the probability of transtion happens.</p>
					</aside>
				</section>
				<section data-auto-animate>
					<h4>Main Challenges</h4>
					<div data-id="EB">
						<p>
							The Prevalence of Energy Barriers <br>
						</p>
					</div>
					<div data-id="EBP" style="font-size: 0.8em;">
						<p>
							<span style="color: #C82423;"> Explore the phase space by overcoming energy barriers </span> 
						</p>
					</div>
					<div data-id="HD">
						<br>
						<p>
							The High Dimensionality 
						<sapn style="color:blue;"> (Open) </sapn>
						</p>
					</div>
					<div style="font-size: 0.7em;">
						<p>
							<font color="#C82423"> Exploite the posterior error to adaptively optimize the sampling ponits.</font>
						</p>
					</div>
					<div style="font-size: 0.7em;">
						<p>
							<sapn style="color:blue;">Recent Attempts</sapn>: Reinforce Dynamics (Uncertainty Indicator+ Multi DNN)
						</p>
					</div>
						<aside class="notes">
							<p> Another difficulty of the reconstruct the FES due to the high dimensionality.</p>
							<p> Towards the high dimensional problem, uniformly sampling all over the space can be computational unachiaible.</p>
							<p> A typical idea is add some adaptives in to the sampling, just like adaptive FEM, you may familar.</p>
							<p> The typical idea is use posterior error enhanced sampling</p>
							<p> The numerical method to achieve this in high dimension function approximate is in general open.</p>
							<p> Some recent attemps to this goal.</p>
							<p> In Rid, multi NN is trained on the same data set</p>
							<p> They hope in large error region the different NN will have different value</p>
							<p> Thus the std of the NN can be used to as an indicator to bias the potential.</p>
							<p> In the present work, we want to develop a method achieve both configuration space exploration and posterior error enhanced sampling</p>
						</aside>
				</section>
				<section data-auto-animate>
					<h4>
						Intuitive Idea
					</h4>
					<div data-id="interproduce">
						<div>
								\(\min_{\mathcal{N}}\max_q \int_\Gamma \MLMN(\bz) q(\bz) \intd\bz\) 
						</div>
						<div style="font-size: 0.8em;">
							<ul>
								<li>
									Minization problem:
								</li>
								optimize the FES on the  given sampled points <br>
								<li>
									<sapn style="color:#C82423;"> 	Maximum problem </sapn>:</li>
									 optimize the Sampling Distribution given the trained FES 
								<li>
									<sapn style="color:#C82423;"> Iteratively solving Minization and Maximation problems gives the constructed FES.</sapn>
								</li>
								</ul>
						</div>
						<div>
							<p style="font-size: 0.8em;">
								\(\MLMN(\bz) = \|-\nabla_\bz A_{\mathcal N}(\bz) - \bF(\bz)\|\): Residual Error
								<br>
								\(
								q(\bz)
								\): Sampling Distribution
								<br>
								\(
									A_{\mathcal N}(\bz)
									\):FES Parameterized
								<br>
									\(
									\bF(\bz)
								\):Force Calculated
							</p>
						</div>
					</div>

					<aside class="notes">
						<p> To achieve this goal, we introduce a min-max problem.</p>
						<p> The min problem is common, give some sampling points in the training set, say they satisfies the distribution q</p>
						<p> we ask minize the loss funtion defined as a L2 error of the negative gradient of parameterized FES and force sampled from full dynamics.</p>
						<p> In max problem, give a trained FES, we want to obtain refine our training set or sampling points</p>
						<p> Intuitively, we want to add more points where error is large, thus we maximize the loss with respect the distribution q</p>
					 </aside>
				</section>
				<section data-auto-animate>
					<h4>
						Maximum Problem
					</h4>
						<div>
							<ul>
								<li>
									Original:
								</li>
								\(\max_q \int - \MLMN(\bz)q(\bz) \intd \bz \) <br>
								Solution: \(\delta(\bz-\bz^*)\)
								<p>
								</p>
								<li>
									<sapn style="color:#C82423;">Entropy regularization:</sapn>
								</li>
							    \(
									\min_{q} \int (\MLMN^-(\bz) + \kappa_h \ln q(\bz)) q(\bz) \intd \bz 
									\) <br>
									Solution: \(q^*(\bz)=\exp(-\kappa_h \MLMN^-(\bz))/Z^*\)
							</ul>
						</div>
						<div>
							<sapn style="color:#C82423;"> How to sampling accoding to \(q^*\)?</sapn>
						</div>
						<div>
							<div>
								<small>
									\[
									\begin{aligned}
									& \text{Maximum Error Point}: & \bz^{\ast} &= \arg\max \MLMN(\bz)\\
									&\text{Negative Residual Error}: &\MLMN^-(\bz) & = -\MLMN(\bz)\\
									\end{aligned}
									\]
								</small>
							</div>
						
					</div>
					<aside class="notes">
						<p> The minization problem is relative common, so we focus on the maximum problem first.</p>
						<p> The solution of the maximum problem is delta function localed at the maximum error points.</p>
						<p> However, this task can not be easily achievable, it's a high dimensional no convex optimization problem.</p>
						<p> It's has a strong connection with the difficulty we mentioned before, the high energy bar on the FES</p>
						<p> So typically we want to add some entropy regularization to give our algorithm some exploration ability</p>
						<p> Also we add a minius sign to make maximation to minization.</p>
						<p>The problem is convex for a Probability Density Function (PDF) \( q \), with a unique global minimum.</p> 
						<p> kappa_h works as a </p>
					 </aside>
				</section>
				<section data-auto-animate>
					<h4>
						Local Quaditical Approximation
					</h4>
					<div style="font-size: 0.6em;">
						\[
						\begin{aligned}
						& \MLMN^-(\bz)  & G(\bz) &=\frac{1}{2} (\bz-\mbm)^T V^{-1}(\bz-\mbm)\\
						&q^*(\bz)=\exp(-\kappa_h \MLMN^-(\bz))/Z^* & \tilde{q}(\bz) &= \exp(-\kappa_h G(\bz))/\tilde{Z}
						\end{aligned}
						\]
					</div>
					<div style="display: flex; justify-content: center; align-items: center;">
					<div>
						
						<div data-id="LDT" style="font-size: 0.8em;">
							Based On the Laplace Principle in Large Deviations Theory
						</div>
						<div style="font-size: 0.6em;">
							\[
							\begin{split}
							&\text{First Momentum: } &\mbm = \int \bz p(\bz)\intd \bz  \approx 
							\sum_{i=1}^{N_w} \mb z^i \hat{p}(\mb z^i) \\
							&\text{Second Momentum: } &V  \text{ to be determined} \\
							&\text{Weighted Distribution: } &\hat{p} (\mb z) =  \frac{\exp {(-\kappa_l \MLMN^-(\bz^i))}}{\sum_{i=1}^{N_w}\exp {(-\kappa_l \MLMN^-(\bz^i)})}\\
							 \end{split}
							\]
						</div>
						<sapn style="color:#C82423;">How many \(N_w\) we need?</sapn>

					</div>
					<div>
						<embed src="./figure/Laplaces_method.svg" type="image/svg+xml"/>  
					</div>
				</section>
				<section data-auto-animate>
					<h4>
						Exploitation and Exploration in McKean stochastic differential equation
					</h4>
					<div>
						\[
						\dot{\bz}^i_t = - \frac{1}{\gamma}\nabla_\bz G(\bz^i_t;\mb m_t ,V_t) + \sqrt{\frac{2}{\kappa_h\gamma}} \mathbf\xi_i(t)
						\]
					</div>
						<div style="font-size: 0.6em;">
							\[
							\begin{aligned}
							&\text{Driven Term}: &G(\bz_t;\mb m_t ,V_t) &=\frac{1}{2} (\bz_t-\mbm_t)^T V_t^{-1}(\bz_t-\mbm_t)\\
							&\text{First Momentum} & \mb m_t & = \sum_{i=1}^{N_{w}}\bz^i_t \hat{p}(\bz^i_t),\\
							&\text{Second Momentum} & V_t & = \kappa_t\sum_{i=1}^{N_{w}} (\bz^i_t-\mbm_t)(\bz^i_t-\mbm_t)^T \hat{p}(\bz^i_t)\\
							&\text{Weighted Distribution} & 
							\hat{p} (\mb z) & =  \frac{\exp {(-\kappa_l \MLMN^-(\bz^i))}}{\sum_{i=1}^{N_w}\exp {(-\kappa_l \MLMN^-(\bz^i)})}
							\end{aligned}
							\]
						</div>

					<aside class="notes">
						  <p>Instead we treat the sampler z as a random walker z^i_t, governed by the McKean stochastic differential equation.</p>
						<p>
							The adaptively constructed conservative potential function \( G(\bz_t) \) guides individual particles towards \( \bm_t \), indicative of the region of large residual error. 
						</p> 

					</aside>
				</section>
				

				<section data-auto-animate>
					<div class="proposition" data-id="proposition1">
						<ul>
							<div>Proposition 1:</div>
							<div class="content">
								Suppose \( \mathcal{L}^- (\mathbf{z}) \) takes a local quadratic approximation in the form of \( \frac{1}{2} (\mathbf{z} - \boldsymbol{\mu})^T \Sigma^{-1} (\mathbf{z} - \boldsymbol{\mu}) \), \( q_t \to \frac{\exp{(-\kappa_h \mathcal{L}^- (\mathbf{z}))}}{\int \exp {(-\kappa_h \mathcal{L}^- (\mathbf{z}))} \, d\mathbf{z}} \) as \( t \to \infty \), given \( \kappa_t = \kappa_l + \kappa_h \).
							</div>
						</ul>
					</div>
				</section>

				<section>
					<div>
						<p>
							<img  style="width:80%" src="./figure/consensus.pdf">
						</p>
					</div>
				</section>
				<section data-auto-animate>
					<h4>
					Numerical Result (2D)
					</h4>
						<div style="display: flex; justify-content: center; align-items: center;">
							<div>
								<small>
								<table>
									<thead>
										<tr>
											<th rowspan="2">Method</th>
											<th colspan="2">Accuracy</th>
											<th colspan="3">Time</th>
										</tr>
										<tr>
											<th>\(l_2\) error</th>
											<th>\(l_\infty\) error</th>
											<th>Simulation</th>
											<th>Train</th>
											<th>Total</th>
										</tr>
									</thead>
									<tbody>
										<tr>
											<td rowspan="2">VES</td>
											<td>5.39</td>
											<td>21.03</td>
											<td colspan="3">47.5</td>
										</tr>
										<tr></tr>
										<tr>
											<td rowspan="2">RiD</td>
											<td>1.52</td>
											<td>9.46</td>
											<td>6.25</td>
											<td>3.79(GPU)</td>
											<td>10.04</td>
										</tr>
										<tr></tr>
										<tr>
											<td rowspan="2">CES</td>
											<td rowspan="2">1.45</td>
											<td rowspan="2">6.74</td>
											<td rowspan="2">0.88 × 10walkers</td>
											<td>0.18(CPU)</td>
											<td>8.98</td>
										</tr>
										<tr>
											<td>0.13(GPU)</td>
											<td>8.93</td>
										</tr>
										<tr></tr>
									</tbody>
								</table>
							</small>
							</div>
						<div
							id=ala2
							class="plotly-graph-div"
							style="height:400; width:400;">
						</div>
						<script type="text/javascript" src="./text/plotly_test.js">
						</script>
					</div>
				</section>
				<section data-auto-animate>
					<h4>Numerical Result (3D)</h4>
					<div style="display: flex; flex-direction: center; align-items: center;">
						<div>
							<small>
								<table border="1" cellspacing="0" cellpadding="8">
									<thead>
										<tr>
											<th rowspan="2">Method</th>
											<th colspan="3">Time</th>
										</tr>
										<tr>
											<th>Simulation</th>
											<th>Train</th>
											<th>Total</th>
										</tr>
									</thead>
									<tbody>
										<tr>
											<td>RiD</td>
											<td>117</td>
											<td>79 (GPU)</td>
											<td>196</td>
										</tr>
										<tr>
											<td>CES</td>
											<td>4.81× 20walkers</td>
											<td>0.66 (GPU)</td>
											<td>97</td>
										</tr>
									</tbody>
								</table>
							</small>
						</div>
						<div style="overflow-y: auto; max-height: 400px;">
							<div id="chi1_psi_15" class="plotly-graph-div" style="height:500px; width:600px;">
								<small>\(\psi=1.5\)</small>
							</div>
							<div id="chi1_phi_10" class="plotly-graph-div" style="height:500px; width:600px;">
								<small>\(\phi=1.0\)</small>
							</div>
							<div id="chi1_ome_15" class="plotly-graph-div" style="height:500px; width:600px;">
								<small>\(\omega=1.5\)</small>
							</div>
							<script type="text/javascript" src="./text/chi1.js"></script>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h4>Numerical Result (30D)</h4>
					<div>

						<div style="overflow-y: auto; max-height: 400px;">
							<div id="phi1_psi1" class="plotly-graph-div" style="height:400px; width:600px; margin: auto;">
								<small>\(\phi_1,\psi_1\)</small>
							</div>
							<div id="phi2_phi3" class="plotly-graph-div" style="height:400px; width:600px; margin: auto;">
								<small>\(\phi_2,\phi_3\)</small>
							</div>
							<div id="psi2_psi3" class="plotly-graph-div" style="height:400px; width:600px; margin: auto;">
								<small>\(\psi_2,\psi_3\)</small>
							</div>
						</div>
						<script type="text/javascript" src="./text/ala16.js"></script>
					</div>
				</section>
				<section data-auto-animate>
					<h4>
						Conclusion
					</h4>
					<ul>
						<li>
							The difficulty of construct FES is not only on overcoming energy barrier but also in <font color="#C82423">high dimensionality</font>.
						</li>
						<li>
							We introduce a <font color="#C82423">posterior errors driven </font>sampling process.
						</li>
					</ul>
				</section>
		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>

	</body>
</html>
